{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.tensor([1, 2])\n",
    "b = torch.tensor([3, 4])\n",
    "c = torch.tensor([3, 4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 3, 3],\n",
       "        [2, 4, 4]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.stack((a, b, c), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 1],\n",
       "        [2, 2]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1], [2]])\n",
    "b = torch.tensor([[1], [2]])\n",
    "\n",
    "torch.cat([a, b], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = [1.0] * 5  # Example class weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "a = [1, 2, torch.tensor(3)]\n",
    "torch.tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA-enabled GPU not found. Exiting...\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "if not cv2.cuda.getCudaEnabledDeviceCount():\n",
    "    print(\"CUDA-enabled GPU not found. Exiting...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4, 0.4, 0.3666666666666666, None)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.array([1, 1, 2, 0, 3, 4, 2])\n",
    "targets = np.array([1, 0, 2, 1, 4, 4, 3])\n",
    "\n",
    "precision_recall_fscore_support(targets, y_pred, average='macro')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\.conda\\envs\\EnvMasoudi\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7, 0.8, 0.7333333333333333, None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = np.array([1, 0, 2, 1, 4, 4, 2])\n",
    "targets = np.array([1, 0, 2, 1, 4, 4, 3])\n",
    "\n",
    "precision_recall_fscore_support(targets, y_pred, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.Tensor([1, 2, 3])\n",
    "b = torch.tensor([1, 2, 3.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2, label_smoothing=0):\n",
    "        super(FocalLoss, self).__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.label_smoothing = label_smoothing\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=self.label_smoothing)\n",
    "        pt = torch.exp(-ce_loss)\n",
    "        loss = (self.alpha[targets] * (1 - pt) ** self.gamma * ce_loss).mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9226, 0.9226])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = torch.tensor([[-2, -5, 3, 6, 12.], [-2, -5, 3, 6, 12.]])\n",
    "targets = torch.tensor([4, 4])\n",
    "\n",
    "ce_loss = F.cross_entropy(inputs, targets, reduction='none', label_smoothing=0.1)\n",
    "ce_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9974, 0.9974])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pt = torch.exp(-ce_loss)\n",
    "pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 3.])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma = 1\n",
    "alpha = torch.tensor([0.2, 5, 3, 2, 3])\n",
    "alpha[targets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0249e-05)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss = (alpha[targets] * (1 - pt) ** gamma * ce_loss).mean()\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.0249e-05)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_fn = FocalLoss(alpha=alpha, gamma=1, label_smoothing=0.0)\n",
    "loss_fn(inputs, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.5000])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = torch.tensor([0.5]) * 5\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 * 3 ** 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "class OneHeadModel(nn.Module):\n",
    "    def __init__(self, device, p_dropout):\n",
    "        super(OneHeadModel, self).__init__()\n",
    "\n",
    "        self.device = device\n",
    "        self.p_dropout = p_dropout\n",
    "\n",
    "        # weights = torchvision.models.ResNeXt50_32X4D_Weights.DEFAULT\n",
    "        # model = torchvision.models.resnext50_32x4d(weights=weights)\n",
    "        # model = torch.nn.Sequential(*(list(model.children())[:-2])) # remove last two layers\n",
    "        # self.encoder = model\n",
    "\n",
    "        # Load EfficientNet encoder\n",
    "        weights = torchvision.models.EfficientNet_B4_Weights.DEFAULT\n",
    "        efficientNet = torchvision.models.efficientnet_b4(weights=weights)\n",
    "        self.encoder = efficientNet.features\n",
    "\n",
    "        # Pooling layers\n",
    "        self.global_max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.global_avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.batch_norm_1= nn.BatchNorm1d(1792) \n",
    "        self.batch_norm_2= nn.BatchNorm1d(1792)\n",
    "\n",
    "        self.dense1 = nn.Sequential(\n",
    "            nn.Linear(1792 * 2, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=self.p_dropout)\n",
    "        )\n",
    "\n",
    "        # Classification head\n",
    "        self.classification_head = nn.Sequential(\n",
    "            nn.Linear(512, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=self.p_dropout),\n",
    "            nn.Linear(32, 5) # 5 output nodes for classification\n",
    "            )\n",
    "        \n",
    "        # Apply He initialization to classification_head\n",
    "        self._initialize_weights()\n",
    "        \n",
    "    def _initialize_weights(self):\n",
    "        \n",
    "        # # Initialize dense1\n",
    "        # nn.init.kaiming_normal_(self.dense1.weight, mode='fan_in', nonlinearity='relu')\n",
    "        # if self.dense1.Linear.bias is not None:\n",
    "        #     nn.init.zeros_(self.dense1.bias)\n",
    "\n",
    "        for module in self.classification_head:\n",
    "            if isinstance(module, nn.Linear):\n",
    "                # Apply He initialization to weights\n",
    "                nn.init.kaiming_normal_(module.weight, mode='fan_in', nonlinearity='relu')\n",
    "                # Initialize biases to zero (optional, common practice)\n",
    "                if module.bias is not None:\n",
    "                    nn.init.zeros_(module.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x) # Extract features\n",
    "\n",
    "        # Apply pooling layers\n",
    "        max_pooled = self.global_max_pool(x).view(x.size(0), -1)\n",
    "        avg_pooled = self.global_avg_pool(x).view(x.size(0), -1)\n",
    "\n",
    "        # Concatenate\n",
    "        x1 = self.batch_norm_1(max_pooled)\n",
    "        x2 = self.batch_norm_2(avg_pooled)\n",
    "        x = torch.concat([x1, x2], dim=1)\n",
    "        print('x in model before relue is: ', x)\n",
    "        x = torch.relu(self.dense1(x))\n",
    "\n",
    "        # enc_out for visualizing data with t-SNE\n",
    "        enc_out = x\n",
    "\n",
    "        # Classification branch\n",
    "        class_out = self.classification_head(x).float()\n",
    "\n",
    "        return class_out, enc_out\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = OneHeadModel(device=torch.device, p_dropout=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "============================================================================================================================================\n",
       "Layer (type (var_name))                                      Input Shape          Output Shape         Param #              Trainable\n",
       "============================================================================================================================================\n",
       "OneHeadModel (OneHeadModel)                                  [32, 3, 240, 240]    [32, 5]              --                   True\n",
       "├─Sequential (encoder)                                       [32, 3, 240, 240]    [32, 1792, 8, 8]     --                   True\n",
       "│    └─Conv2dNormActivation (0)                              [32, 3, 240, 240]    [32, 48, 120, 120]   --                   True\n",
       "│    │    └─Conv2d (0)                                       [32, 3, 240, 240]    [32, 48, 120, 120]   1,296                True\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 48, 120, 120]   [32, 48, 120, 120]   96                   True\n",
       "│    │    └─SiLU (2)                                         [32, 48, 120, 120]   [32, 48, 120, 120]   --                   --\n",
       "│    └─Sequential (1)                                        [32, 48, 120, 120]   [32, 24, 120, 120]   --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 48, 120, 120]   [32, 24, 120, 120]   2,940                True\n",
       "│    │    └─MBConv (1)                                       [32, 24, 120, 120]   [32, 24, 120, 120]   1,206                True\n",
       "│    └─Sequential (2)                                        [32, 24, 120, 120]   [32, 32, 60, 60]     --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 24, 120, 120]   [32, 32, 60, 60]     11,878               True\n",
       "│    │    └─MBConv (1)                                       [32, 32, 60, 60]     [32, 32, 60, 60]     18,120               True\n",
       "│    │    └─MBConv (2)                                       [32, 32, 60, 60]     [32, 32, 60, 60]     18,120               True\n",
       "│    │    └─MBConv (3)                                       [32, 32, 60, 60]     [32, 32, 60, 60]     18,120               True\n",
       "│    └─Sequential (3)                                        [32, 32, 60, 60]     [32, 56, 30, 30]     --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 32, 60, 60]     [32, 56, 30, 30]     25,848               True\n",
       "│    │    └─MBConv (1)                                       [32, 56, 30, 30]     [32, 56, 30, 30]     57,246               True\n",
       "│    │    └─MBConv (2)                                       [32, 56, 30, 30]     [32, 56, 30, 30]     57,246               True\n",
       "│    │    └─MBConv (3)                                       [32, 56, 30, 30]     [32, 56, 30, 30]     57,246               True\n",
       "│    └─Sequential (4)                                        [32, 56, 30, 30]     [32, 112, 15, 15]    --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 56, 30, 30]     [32, 112, 15, 15]    70,798               True\n",
       "│    │    └─MBConv (1)                                       [32, 112, 15, 15]    [32, 112, 15, 15]    197,820              True\n",
       "│    │    └─MBConv (2)                                       [32, 112, 15, 15]    [32, 112, 15, 15]    197,820              True\n",
       "│    │    └─MBConv (3)                                       [32, 112, 15, 15]    [32, 112, 15, 15]    197,820              True\n",
       "│    │    └─MBConv (4)                                       [32, 112, 15, 15]    [32, 112, 15, 15]    197,820              True\n",
       "│    │    └─MBConv (5)                                       [32, 112, 15, 15]    [32, 112, 15, 15]    197,820              True\n",
       "│    └─Sequential (5)                                        [32, 112, 15, 15]    [32, 160, 15, 15]    --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 112, 15, 15]    [32, 160, 15, 15]    240,924              True\n",
       "│    │    └─MBConv (1)                                       [32, 160, 15, 15]    [32, 160, 15, 15]    413,160              True\n",
       "│    │    └─MBConv (2)                                       [32, 160, 15, 15]    [32, 160, 15, 15]    413,160              True\n",
       "│    │    └─MBConv (3)                                       [32, 160, 15, 15]    [32, 160, 15, 15]    413,160              True\n",
       "│    │    └─MBConv (4)                                       [32, 160, 15, 15]    [32, 160, 15, 15]    413,160              True\n",
       "│    │    └─MBConv (5)                                       [32, 160, 15, 15]    [32, 160, 15, 15]    413,160              True\n",
       "│    └─Sequential (6)                                        [32, 160, 15, 15]    [32, 272, 8, 8]      --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 160, 15, 15]    [32, 272, 8, 8]      520,904              True\n",
       "│    │    └─MBConv (1)                                       [32, 272, 8, 8]      [32, 272, 8, 8]      1,159,332            True\n",
       "│    │    └─MBConv (2)                                       [32, 272, 8, 8]      [32, 272, 8, 8]      1,159,332            True\n",
       "│    │    └─MBConv (3)                                       [32, 272, 8, 8]      [32, 272, 8, 8]      1,159,332            True\n",
       "│    │    └─MBConv (4)                                       [32, 272, 8, 8]      [32, 272, 8, 8]      1,159,332            True\n",
       "│    │    └─MBConv (5)                                       [32, 272, 8, 8]      [32, 272, 8, 8]      1,159,332            True\n",
       "│    │    └─MBConv (6)                                       [32, 272, 8, 8]      [32, 272, 8, 8]      1,159,332            True\n",
       "│    │    └─MBConv (7)                                       [32, 272, 8, 8]      [32, 272, 8, 8]      1,159,332            True\n",
       "│    └─Sequential (7)                                        [32, 272, 8, 8]      [32, 448, 8, 8]      --                   True\n",
       "│    │    └─MBConv (0)                                       [32, 272, 8, 8]      [32, 448, 8, 8]      1,420,804            True\n",
       "│    │    └─MBConv (1)                                       [32, 448, 8, 8]      [32, 448, 8, 8]      3,049,200            True\n",
       "│    └─Conv2dNormActivation (8)                              [32, 448, 8, 8]      [32, 1792, 8, 8]     --                   True\n",
       "│    │    └─Conv2d (0)                                       [32, 448, 8, 8]      [32, 1792, 8, 8]     802,816              True\n",
       "│    │    └─BatchNorm2d (1)                                  [32, 1792, 8, 8]     [32, 1792, 8, 8]     3,584                True\n",
       "│    │    └─SiLU (2)                                         [32, 1792, 8, 8]     [32, 1792, 8, 8]     --                   --\n",
       "├─AdaptiveMaxPool2d (global_max_pool)                        [32, 1792, 8, 8]     [32, 1792, 1, 1]     --                   --\n",
       "├─AdaptiveAvgPool2d (global_avg_pool)                        [32, 1792, 8, 8]     [32, 1792, 1, 1]     --                   --\n",
       "├─BatchNorm1d (batch_norm_1)                                 [32, 1792]           [32, 1792]           3,584                True\n",
       "├─BatchNorm1d (batch_norm_2)                                 [32, 1792]           [32, 1792]           3,584                True\n",
       "├─Sequential (dense1)                                        [32, 3584]           [32, 512]            --                   True\n",
       "│    └─Linear (0)                                            [32, 3584]           [32, 512]            1,835,520            True\n",
       "│    └─ReLU (1)                                              [32, 512]            [32, 512]            --                   --\n",
       "│    └─Dropout (2)                                           [32, 512]            [32, 512]            --                   --\n",
       "├─Sequential (classification_head)                           [32, 512]            [32, 5]              --                   True\n",
       "│    └─Linear (0)                                            [32, 512]            [32, 32]             16,416               True\n",
       "│    └─ReLU (1)                                              [32, 32]             [32, 32]             --                   --\n",
       "│    └─Dropout (2)                                           [32, 32]             [32, 32]             --                   --\n",
       "│    └─Linear (3)                                            [32, 32]             [32, 5]              165                  True\n",
       "============================================================================================================================================\n",
       "Total params: 19,407,885\n",
       "Trainable params: 19,407,885\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (Units.GIGABYTES): 58.00\n",
       "============================================================================================================================================\n",
       "Input size (MB): 22.12\n",
       "Forward/backward pass size (MB): 10157.75\n",
       "Params size (MB): 77.63\n",
       "Estimated Total Size (MB): 10257.50\n",
       "============================================================================================================================================"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print a summary using torchinfo (uncomment for actual output)\n",
    "torch.manual_seed(33)\n",
    "summary(model=model, \n",
    "        input_size=(32, 3, 240, 240), # make sure this is \"input_size\", not \"input_shape\"\n",
    "        col_names=[\"input_size\", \"output_size\", \"num_params\", \"trainable\"],\n",
    "        col_width=20,\n",
    "        row_settings=[\"var_names\"]\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
